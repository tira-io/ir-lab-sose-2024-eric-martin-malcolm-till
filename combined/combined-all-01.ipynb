{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IR Lab SoSe 2024: Combined Retrieval System\n",
    "\n",
    "This jupyter notebook serves as an improved retrieval system combining components from both provided notebooks.\n",
    "We will use a corpus of scientific papers (title + abstracts) from the fields of information retrieval and natural language processing (the [IR Anthology](https://ir.webis.de/anthology/) and the [ACL Anthology](https://aclanthology.org/)). This notebook serves as a retrieval system, i.e., it gets a set of information needs (topics) and a corpus as input and produces a run file as output. Please do evaluations in a new dedicated notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Install Required Packages\n",
    "\n",
    "Execute this cell if you're using Google Colab or if you haven't installed these packages yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tira in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (0.0.134)\n",
      "Requirement already satisfied: ir-datasets in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (0.5.5)\n",
      "Requirement already satisfied: python-terrier in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (0.10.0)\n",
      "Requirement already satisfied: transformers in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (4.41.2)\n",
      "Requirement already satisfied: torch in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: nltk in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: requests==2.*,>=2.26 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from tira) (2.32.3)\n",
      "Requirement already satisfied: docker==7.*,>=7.1.0 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from tira) (7.1.0)\n",
      "Requirement already satisfied: numpy==1.* in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from tira) (1.26.2)\n",
      "Requirement already satisfied: pandas in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from tira) (2.1.3)\n",
      "Requirement already satisfied: packaging in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from tira) (24.1)\n",
      "Requirement already satisfied: tqdm in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from tira) (4.66.4)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from docker==7.*,>=7.1.0->tira) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from requests==2.*,>=2.26->tira) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from requests==2.*,>=2.26->tira) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from requests==2.*,>=2.26->tira) (2024.6.2)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from ir-datasets) (4.12.3)\n",
      "Requirement already satisfied: inscriptis>=2.2.0 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from ir-datasets) (2.5.0)\n",
      "Requirement already satisfied: lxml>=4.5.2 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from ir-datasets) (5.2.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from ir-datasets) (6.0.1)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from ir-datasets) (2.6)\n",
      "Requirement already satisfied: lz4>=3.1.10 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from ir-datasets) (4.3.3)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from ir-datasets) (0.2.3)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from ir-datasets) (0.2.5)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from ir-datasets) (0.1.6)\n",
      "Requirement already satisfied: ijson>=3.1.3 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from ir-datasets) (3.3.0)\n",
      "Requirement already satisfied: pyautocorpus>=0.1.1 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from ir-datasets) (0.1.12)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from ir-datasets) (0.2.2)\n",
      "Requirement already satisfied: wget in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from python-terrier) (3.2)\n",
      "Requirement already satisfied: pyjnius>=1.4.2 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from python-terrier) (1.6.1)\n",
      "Requirement already satisfied: matchpy in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from python-terrier) (0.5.5)\n",
      "Requirement already satisfied: scikit-learn in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from python-terrier) (1.5.0)\n",
      "Requirement already satisfied: deprecated in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from python-terrier) (1.2.14)\n",
      "Requirement already satisfied: chest in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from python-terrier) (0.2.3)\n",
      "Requirement already satisfied: scipy in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from python-terrier) (1.14.0)\n",
      "Requirement already satisfied: joblib in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from python-terrier) (1.4.2)\n",
      "Requirement already satisfied: nptyping==1.4.4 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from python-terrier) (1.4.4)\n",
      "Requirement already satisfied: more-itertools in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from python-terrier) (10.3.0)\n",
      "Requirement already satisfied: jinja2 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from python-terrier) (3.1.4)\n",
      "Requirement already satisfied: statsmodels in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from python-terrier) (0.14.2)\n",
      "Requirement already satisfied: ir-measures>=0.3.1 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from python-terrier) (0.3.3)\n",
      "Requirement already satisfied: dill in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from python-terrier) (0.3.8)\n",
      "Requirement already satisfied: pytrec-eval-terrier>=0.5.3 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from python-terrier) (0.5.6)\n",
      "Requirement already satisfied: typish>=1.7.0 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from nptyping==1.4.4->python-terrier) (1.9.3)\n",
      "Requirement already satisfied: filelock in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: fsspec in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: click in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from beautifulsoup4>=4.4.1->ir-datasets) (2.5)\n",
      "Requirement already satisfied: cwl-eval>=1.0.10 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from ir-measures>=0.3.1->python-terrier) (1.0.12)\n",
      "Requirement already satisfied: cbor>=1.0.0 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from trec-car-tools>=2.5.4->ir-datasets) (1.0.0)\n",
      "Requirement already satisfied: heapdict in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from chest->python-terrier) (1.0.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from deprecated->python-terrier) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from jinja2->python-terrier) (2.1.5)\n",
      "Requirement already satisfied: multiset<3.0,>=2.0 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from matchpy->python-terrier) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from pandas->tira) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from pandas->tira) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from pandas->tira) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from scikit-learn->python-terrier) (3.5.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from statsmodels->python-terrier) (0.5.6)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six in /Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages (from patsy>=0.5.6->statsmodels->python-terrier) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tira ir-datasets python-terrier transformers torch nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martinschlenk/Desktop/IRS-combined/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/martinschlenk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "PyTerrier 0.10.0 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "from tira.rest_api_client import Client\n",
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "import os\n",
    "from transformers import BertTokenizer, BertForTokenClassification, pipeline\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize PyTerrier and TIRA client\n",
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset and the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Index loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # The dataset: the union of the IR Anthology and the ACL Anthology\n",
    "    pt_dataset = pt.get_dataset('irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training')\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "\n",
    "    # A (pre-built) PyTerrier index loaded from TIRA\n",
    "    index = tira.pt.index('ir-lab-sose-2024/tira-ir-starter/Index (tira-ir-starter-pyterrier)', pt_dataset)\n",
    "    print(\"Index loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the dataset or index: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Retrieval Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval pipeline defined successfully.\n"
     ]
    }
   ],
   "source": [
    "# Base retrieval model with BM25\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "\n",
    "# Query expansion with Bo1\n",
    "# fb_docs: number of feedback documents, fb_terms: number of expansion terms\n",
    "bo1_expansion = pt.rewrite.Bo1QueryExpansion(index, fb_docs=10, fb_terms=20)\n",
    "bm25_bo1 = bm25 >> bo1_expansion >> bm25\n",
    "\n",
    "# Additional reranking models\n",
    "tf_idf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n",
    "dirichletLM = pt.BatchRetrieve(index, wmodel=\"DirichletLM\")\n",
    "\n",
    "# Combined retrieval pipeline\n",
    "# We're giving more weight to TF-IDF and DirichletLM models\n",
    "combined_pipeline = bm25_bo1 + 2 * tf_idf + 2 * dirichletLM\n",
    "\n",
    "print(\"Retrieval pipeline defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create the Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First, we have a short look at the first three topics:\n",
      "  qid                                     query\n",
      "0   1  retrieval system improving effectiveness\n",
      "1   2  machine learning language identification\n",
      "2   3             social media detect self harm\n",
      "\n",
      "Initializing BERT model for Named Entity Recognition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Segmenting the queries...\n",
      "  qid                                     query\n",
      "0   1  retrieval system improving effectiveness\n",
      "1   2                          machine learning\n",
      "2   3             social media detect self harm\n",
      "\n",
      "Now we do the retrieval...\n",
      "\n",
      "Done. Here are the first 10 entries of the run\n",
      "  qid     docid                                       docno      score  \\\n",
      "0   1   94858.0                2004.cikm_conference-2004.47  41.726132   \n",
      "1   1   94415.0               2008.cikm_conference-2008.183  37.286952   \n",
      "2   1  124801.0           2006.ipm_journal-ir0volumeA42A3.2  36.632425   \n",
      "3   1   17496.0                                    O01-2005  36.026305   \n",
      "4   1   82472.0             1998.sigirconf_conference-98.15  35.786096   \n",
      "5   1   82490.0             1998.sigirconf_conference-98.33  35.791673   \n",
      "6   1   74513.0                 2001.clef_workshop-2001w.24  34.150032   \n",
      "7   1  125137.0           1989.ipm_journal-ir0volumeA25A4.2  34.147797   \n",
      "8   1  125817.0          2005.ipm_journal-ir0volumeA41A5.11  35.869904   \n",
      "9   1  114223.0  2014.wwwjournals_journal-ir0volumeA17A4.15  33.782619   \n",
      "\n",
      "                                    query_0  \\\n",
      "0  retrieval system improving effectiveness   \n",
      "1  retrieval system improving effectiveness   \n",
      "2  retrieval system improving effectiveness   \n",
      "3  retrieval system improving effectiveness   \n",
      "4  retrieval system improving effectiveness   \n",
      "5  retrieval system improving effectiveness   \n",
      "6  retrieval system improving effectiveness   \n",
      "7  retrieval system improving effectiveness   \n",
      "8  retrieval system improving effectiveness   \n",
      "9  retrieval system improving effectiveness   \n",
      "\n",
      "                                               query  rank  \n",
      "0  applypipeline:off retriev^1.221462101 system^1...     0  \n",
      "1  applypipeline:off retriev^1.221462101 system^1...     1  \n",
      "2  applypipeline:off retriev^1.221462101 system^1...     2  \n",
      "3  applypipeline:off retriev^1.221462101 system^1...     3  \n",
      "4  applypipeline:off retriev^1.221462101 system^1...     6  \n",
      "5  applypipeline:off retriev^1.221462101 system^1...     5  \n",
      "6  applypipeline:off retriev^1.221462101 system^1...    12  \n",
      "7  applypipeline:off retriev^1.221462101 system^1...    13  \n",
      "8  applypipeline:off retriev^1.221462101 system^1...     4  \n",
      "9  applypipeline:off retriev^1.221462101 system^1...    15  \n"
     ]
    }
   ],
   "source": [
    "print('First, we have a short look at the first three topics:')\n",
    "topics = pt_dataset.get_topics('text')\n",
    "print(topics.head(3))\n",
    "\n",
    "# Query Segmentation\n",
    "print('\\nInitializing BERT model for Named Entity Recognition...')\n",
    "tokenizer = BertTokenizer.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "model = BertForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Domain-specific terms for query segmentation\n",
    "domain_specific_terms = [\n",
    "    \"natural language processing\", \"NLP\", \"information retrieval\", \"IR\",\n",
    "    \"machine learning\", \"deep learning\", \"neural network\", \"text mining\",\n",
    "    \"language model\", \"BERT\", \"transformer\", \"word embeddings\", \"semantic search\",\n",
    "    \"question answering\", \"text classification\", \"entity recognition\",\n",
    "    \"tokenization\", \"part-of-speech tagging\", \"POS tagging\", \"named entity recognition\", \"NER\",\n",
    "    \"sentiment analysis\", \"topic modeling\", \"latent Dirichlet allocation\", \"LDA\",\n",
    "    \"vector space model\", \"TF-IDF\", \"BM25\", \"relevance feedback\",\n",
    "    \"information retrieval evaluation\", \"precision\", \"recall\", \"F1 score\",\n",
    "    \"mean average precision\", \"MAP\", \"normalized discounted cumulative gain\", \"nDCG\",\n",
    "    \"word2vec\", \"GloVe\", \"fastText\", \"attention mechanism\",\n",
    "    \"sequence-to-sequence\", \"seq2seq\", \"encoder-decoder\", \"automatic summarization\",\n",
    "    \"machine translation\", \"language generation\", \"dialogue systems\", \"chatbots\",\n",
    "    \"cross-lingual information retrieval\", \"multilingual models\", \"transfer learning\",\n",
    "    \"fine-tuning\", \"pre-trained models\", \"zero-shot learning\",\n",
    "    \"few-shot learning\", \"domain adaptation\", \"semi-supervised learning\",\n",
    "    \"unsupervised learning\", \"self-supervised learning\", \"contrastive learning\",\n",
    "    \"contextual embeddings\", \"contextualized word representations\",\n",
    "    \"transformer-based models\", \"convolutional neural networks\", \"CNNs\",\n",
    "    \"recurrent neural networks\", \"RNNs\", \"long short-term memory\", \"LSTM\",\n",
    "    \"gated recurrent units\", \"GRU\", \"sequence labeling\", \"dependency parsing\",\n",
    "    \"constituency parsing\", \"syntactic parsing\", \"semantic parsing\",\n",
    "    \"coreference resolution\", \"relation extraction\", \"information extraction\",\n",
    "    \"knowledge graphs\", \"ontologies\", \"semantic role labeling\", \"SRL\",\n",
    "    \"document retrieval\", \"passage retrieval\", \"question answering systems\",\n",
    "    \"retrieval-augmented generation\", \"RAG\", \"open-domain QA\", \"closed-domain QA\",\n",
    "    \"query expansion\", \"query reformulation\", \"interactive information retrieval\",\n",
    "    \"user modeling\", \"personalized search\", \"context-aware retrieval\",\n",
    "    \"query understanding\", \"query intent\", \"search engine optimization\", \"SEO\",\n",
    "    \"click-through rate\", \"CTR\", \"session-based search\", \"search result diversification\",\n",
    "    \"exploratory search\", \"faceted search\", \"enterprise search\",\n",
    "    \"legal information retrieval\", \"medical information retrieval\",\n",
    "    \"scientific information retrieval\", \"scholarly search\", \"academic search\",\n",
    "    \"digital libraries\", \"citation analysis\", \"bibliometrics\", \"altmetrics\",\n",
    "    \"author disambiguation\", \"document clustering\", \"document classification\",\n",
    "    \"information visualization\", \"search interfaces\", \"human-computer interaction\",\n",
    "    \"HCI\", \"recommendation systems\", \"collaborative filtering\", \"content-based filtering\",\n",
    "    \"hybrid recommendation\", \"ranking algorithms\", \"learning to rank\", \"LTR\",\n",
    "    \"pairwise ranking\", \"listwise ranking\", \"pointwise ranking\", \"click models\",\n",
    "    \"user feedback\", \"implicit feedback\", \"explicit feedback\", \"active learning\",\n",
    "    \"crowdsourcing\", \"data annotation\", \"evaluation metrics\", \"benchmark datasets\"\n",
    "]\n",
    "\n",
    "def advanced_segment_query(query):\n",
    "    ner_results = nlp(query)\n",
    "    segments = set(result['word'] for result in ner_results if result['entity'] in ['B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'])\n",
    "    for term in domain_specific_terms:\n",
    "        if term.lower() in query.lower():  # Case-insensitive matching\n",
    "            segments.add(term)\n",
    "    if not segments:\n",
    "        segments = word_tokenize(query)\n",
    "    return \" \".join(segments)\n",
    "\n",
    "print('\\nSegmenting the queries...')\n",
    "segmented_topics = topics.copy()\n",
    "segmented_topics['query'] = segmented_topics['query'].apply(advanced_segment_query)\n",
    "print(segmented_topics.head(3))\n",
    "\n",
    "print('\\nNow we do the retrieval...')\n",
    "run = combined_pipeline.transform(segmented_topics)\n",
    "\n",
    "print('\\nDone. Here are the first 10 entries of the run')\n",
    "print(run.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Persist the run file for subsequent evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../runs\".\n",
      "Done. run file is stored under \"../runs/run.txt\".\n",
      "Run file is stored under \"../runs/run.txt\".\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.makedirs('../runs', exist_ok=True)\n",
    "    persist_and_normalize_run(run, system_name='combined-bm25-bo1-tfidf-dirichlet', default_output='../runs')\n",
    "    print('Run file is stored under \"../runs/run.txt\".')\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while saving the run file: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
