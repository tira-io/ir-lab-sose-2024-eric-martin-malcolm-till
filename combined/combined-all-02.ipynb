{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IR Lab SoSe 2024: Combined Retrieval System\n",
    "\n",
    "This jupyter notebook serves as an improved retrieval system combining components from both provided notebooks.\n",
    "We will use a corpus of scientific papers (title + abstracts) from the fields of information retrieval and natural language processing (the [IR Anthology](https://ir.webis.de/anthology/) and the [ACL Anthology](https://aclanthology.org/)). This notebook serves as a retrieval system, i.e., it gets a set of information needs (topics) and a corpus as input and produces a run file as output. Please do evaluations in a new dedicated notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Install Required Packages and Setup Logging\n",
    "\n",
    "Execute this cell if you're using Google Colab or if you haven't installed these packages yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tira in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (0.0.134)\n",
      "Requirement already satisfied: ir-datasets in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (0.5.5)\n",
      "Requirement already satisfied: python-terrier in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (0.10.0)\n",
      "Requirement already satisfied: transformers in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (4.41.2)\n",
      "Requirement already satisfied: torch in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: nltk in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: requests==2.*,>=2.26 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from tira) (2.32.3)\n",
      "Requirement already satisfied: docker==7.*,>=7.1.0 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from tira) (7.1.0)\n",
      "Requirement already satisfied: numpy==1.* in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from tira) (1.26.2)\n",
      "Requirement already satisfied: pandas in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from tira) (2.1.3)\n",
      "Requirement already satisfied: packaging in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from tira) (24.1)\n",
      "Requirement already satisfied: tqdm in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from tira) (4.66.4)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from docker==7.*,>=7.1.0->tira) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from requests==2.*,>=2.26->tira) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from requests==2.*,>=2.26->tira) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from requests==2.*,>=2.26->tira) (2024.6.2)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from ir-datasets) (4.12.3)\n",
      "Requirement already satisfied: inscriptis>=2.2.0 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from ir-datasets) (2.5.0)\n",
      "Requirement already satisfied: lxml>=4.5.2 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from ir-datasets) (5.2.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from ir-datasets) (6.0.1)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from ir-datasets) (2.6)\n",
      "Requirement already satisfied: lz4>=3.1.10 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from ir-datasets) (4.3.3)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from ir-datasets) (0.2.3)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from ir-datasets) (0.2.5)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from ir-datasets) (0.1.6)\n",
      "Requirement already satisfied: ijson>=3.1.3 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from ir-datasets) (3.3.0)\n",
      "Requirement already satisfied: pyautocorpus>=0.1.1 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from ir-datasets) (0.1.12)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from ir-datasets) (0.2.2)\n",
      "Requirement already satisfied: wget in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from python-terrier) (3.2)\n",
      "Requirement already satisfied: pyjnius>=1.4.2 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from python-terrier) (1.6.1)\n",
      "Requirement already satisfied: matchpy in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from python-terrier) (0.5.5)\n",
      "Requirement already satisfied: scikit-learn in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from python-terrier) (1.5.0)\n",
      "Requirement already satisfied: deprecated in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from python-terrier) (1.2.14)\n",
      "Requirement already satisfied: chest in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from python-terrier) (0.2.3)\n",
      "Requirement already satisfied: scipy in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from python-terrier) (1.14.0)\n",
      "Requirement already satisfied: joblib in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from python-terrier) (1.4.2)\n",
      "Requirement already satisfied: nptyping==1.4.4 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from python-terrier) (1.4.4)\n",
      "Requirement already satisfied: more-itertools in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from python-terrier) (10.3.0)\n",
      "Requirement already satisfied: jinja2 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from python-terrier) (3.1.4)\n",
      "Requirement already satisfied: statsmodels in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from python-terrier) (0.14.2)\n",
      "Requirement already satisfied: ir-measures>=0.3.1 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from python-terrier) (0.3.3)\n",
      "Requirement already satisfied: dill in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from python-terrier) (0.3.8)\n",
      "Requirement already satisfied: pytrec-eval-terrier>=0.5.3 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from python-terrier) (0.5.6)\n",
      "Requirement already satisfied: typish>=1.7.0 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from nptyping==1.4.4->python-terrier) (1.9.3)\n",
      "Requirement already satisfied: filelock in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: fsspec in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: click in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from beautifulsoup4>=4.4.1->ir-datasets) (2.5)\n",
      "Requirement already satisfied: cwl-eval>=1.0.10 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from ir-measures>=0.3.1->python-terrier) (1.0.12)\n",
      "Requirement already satisfied: cbor>=1.0.0 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from trec-car-tools>=2.5.4->ir-datasets) (1.0.0)\n",
      "Requirement already satisfied: heapdict in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from chest->python-terrier) (1.0.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from deprecated->python-terrier) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from jinja2->python-terrier) (2.1.5)\n",
      "Requirement already satisfied: multiset<3.0,>=2.0 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from matchpy->python-terrier) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from pandas->tira) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from pandas->tira) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from pandas->tira) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from scikit-learn->python-terrier) (3.5.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from statsmodels->python-terrier) (0.5.6)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six in /Users/martinschlenk/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages (from patsy>=0.5.6->statsmodels->python-terrier) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Logging initialized.\n"
     ]
    }
   ],
   "source": [
    "!pip install tira ir-datasets python-terrier transformers torch nltk\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.info(\"Logging initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/martinschlenk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "INFO:root:Due to execution in TIRA, I have patched ir_datasets to always return the single input dataset mounted to the sandbox.\n",
      "INFO:root:No settings given in /Users/martinschlenk/.tira/.tira-settings.json. I will use defaults.\n",
      "INFO:root:No settings given in /Users/martinschlenk/.tira/.tira-settings.json. I will use defaults.\n",
      "INFO:root:Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "from tira.rest_api_client import Client\n",
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "import os\n",
    "from transformers import BertTokenizer, BertForTokenClassification, pipeline\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize PyTerrier and TIRA client\n",
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()\n",
    "\n",
    "logging.info(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset and the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dataset loaded successfully.\n",
      "INFO:root:Index loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # The dataset: the union of the IR Anthology and the ACL Anthology\n",
    "    pt_dataset = pt.get_dataset('irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training')\n",
    "    logging.info(\"Dataset loaded successfully.\")\n",
    "\n",
    "    # A (pre-built) PyTerrier index loaded from TIRA\n",
    "    index = tira.pt.index('ir-lab-sose-2024/tira-ir-starter/Index (tira-ir-starter-pyterrier)', pt_dataset)\n",
    "    logging.info(\"Index loaded successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred while loading the dataset or index: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Retrieval Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Retrieval pipeline defined successfully.\n"
     ]
    }
   ],
   "source": [
    "# Base retrieval model with BM25\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "\n",
    "# Query expansion with Bo1\n",
    "# fb_docs: number of feedback documents, fb_terms: number of expansion terms\n",
    "bo1_expansion = pt.rewrite.Bo1QueryExpansion(index, fb_docs=10, fb_terms=20)\n",
    "bm25_bo1 = bm25 >> bo1_expansion >> bm25\n",
    "\n",
    "# Additional reranking models\n",
    "tf_idf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n",
    "dirichletLM = pt.BatchRetrieve(index, wmodel=\"DirichletLM\")\n",
    "\n",
    "# Combined retrieval pipeline\n",
    "# We're giving more weight to TF-IDF and DirichletLM models\n",
    "combined_pipeline = bm25_bo1 + 2 * tf_idf + 2 * dirichletLM\n",
    "\n",
    "logging.info(\"Retrieval pipeline defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create the Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First, we have a short look at the first three topics:\n",
      "  qid                                     query\n",
      "0   1  retrieval system improving effectiveness\n",
      "1   2  machine learning language identification\n",
      "2   3             social media detect self harm\n",
      "\n",
      "Initializing BERT model for Named Entity Recognition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "INFO:root:BERT model loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Segmenting the queries...\n",
      "  qid                                     query\n",
      "0   1  retrieval system improving effectiveness\n",
      "1   2                          machine learning\n",
      "2   3             social media detect self harm\n",
      "\n",
      " Now we do the retrieval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Could not save to /output: Cannot save file into a non-existent directory: '/output'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Done. Here are the first 10 entries of the run\n",
      "  qid     docid                                       docno      score  \\\n",
      "0   1   94858.0                2004.cikm_conference-2004.47  41.726132   \n",
      "1   1   94415.0               2008.cikm_conference-2008.183  37.286952   \n",
      "2   1  124801.0           2006.ipm_journal-ir0volumeA42A3.2  36.632425   \n",
      "3   1   17496.0                                    O01-2005  36.026305   \n",
      "4   1   82472.0             1998.sigirconf_conference-98.15  35.786096   \n",
      "5   1   82490.0             1998.sigirconf_conference-98.33  35.791673   \n",
      "6   1   74513.0                 2001.clef_workshop-2001w.24  34.150032   \n",
      "7   1  125137.0           1989.ipm_journal-ir0volumeA25A4.2  34.147797   \n",
      "8   1  125817.0          2005.ipm_journal-ir0volumeA41A5.11  35.869904   \n",
      "9   1  114223.0  2014.wwwjournals_journal-ir0volumeA17A4.15  33.782619   \n",
      "\n",
      "                                    query_0  \\\n",
      "0  retrieval system improving effectiveness   \n",
      "1  retrieval system improving effectiveness   \n",
      "2  retrieval system improving effectiveness   \n",
      "3  retrieval system improving effectiveness   \n",
      "4  retrieval system improving effectiveness   \n",
      "5  retrieval system improving effectiveness   \n",
      "6  retrieval system improving effectiveness   \n",
      "7  retrieval system improving effectiveness   \n",
      "8  retrieval system improving effectiveness   \n",
      "9  retrieval system improving effectiveness   \n",
      "\n",
      "                                               query  rank  \n",
      "0  applypipeline:off retriev^1.221462101 system^1...     0  \n",
      "1  applypipeline:off retriev^1.221462101 system^1...     1  \n",
      "2  applypipeline:off retriev^1.221462101 system^1...     2  \n",
      "3  applypipeline:off retriev^1.221462101 system^1...     3  \n",
      "4  applypipeline:off retriev^1.221462101 system^1...     6  \n",
      "5  applypipeline:off retriev^1.221462101 system^1...     5  \n",
      "6  applypipeline:off retriev^1.221462101 system^1...    12  \n",
      "7  applypipeline:off retriev^1.221462101 system^1...    13  \n",
      "8  applypipeline:off retriev^1.221462101 system^1...     4  \n",
      "9  applypipeline:off retriev^1.221462101 system^1...    15  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Results saved to ../runs/run.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../runs\".\n",
      "Done. run file is stored under \"../runs/run.txt\".\n"
     ]
    }
   ],
   "source": [
    "print('First, we have a short look at the first three topics:')\n",
    "topics = pt_dataset.get_topics('text')\n",
    "print(topics.head(3))\n",
    "\n",
    "# Query Segmentation\n",
    "try:\n",
    "    print('\\nInitializing BERT model for Named Entity Recognition...')\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "    model = BertForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "    nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "    logging.info('BERT model loaded successfully')\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading BERT model: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Domain-specific terms for query segmentation\n",
    "domain_specific_terms = [\n",
    "    \"natural language processing\", \"NLP\", \"information retrieval\", \"IR\",\n",
    "    \"machine learning\", \"deep learning\", \"neural network\", \"text mining\",\n",
    "    \"language model\", \"BERT\", \"transformer\", \"word embeddings\", \"semantic search\",\n",
    "    \"question answering\", \"text classification\", \"entity recognition\",\n",
    "    \"tokenization\", \"part-of-speech tagging\", \"POS tagging\", \"named entity recognition\", \"NER\",\n",
    "    \"sentiment analysis\", \"topic modeling\", \"latent Dirichlet allocation\", \"LDA\",\n",
    "    \"vector space model\", \"TF-IDF\", \"BM25\", \"relevance feedback\",\n",
    "    \"information retrieval evaluation\", \"precision\", \"recall\", \"F1 score\",\n",
    "    \"mean average precision\", \"MAP\", \"normalized discounted cumulative gain\", \"nDCG\",\n",
    "    \"word2vec\", \"GloVe\", \"fastText\", \"attention mechanism\",\n",
    "    \"sequence-to-sequence\", \"seq2seq\", \"encoder-decoder\", \"automatic summarization\",\n",
    "    \"machine translation\", \"language generation\", \"dialogue systems\", \"chatbots\",\n",
    "    \"cross-lingual information retrieval\", \"multilingual models\", \"transfer learning\",\n",
    "    \"fine-tuning\", \"pre-trained models\", \"zero-shot learning\",\n",
    "    \"few-shot learning\", \"domain adaptation\", \"semi-supervised learning\",\n",
    "    \"unsupervised learning\", \"self-supervised learning\", \"contrastive learning\",\n",
    "    \"contextual embeddings\", \"contextualized word representations\",\n",
    "    \"transformer-based models\", \"convolutional neural networks\", \"CNNs\",\n",
    "    \"recurrent neural networks\", \"RNNs\", \"long short-term memory\", \"LSTM\",\n",
    "    \"gated recurrent units\", \"GRU\", \"sequence labeling\", \"dependency parsing\",\n",
    "    \"constituency parsing\", \"syntactic parsing\", \"semantic parsing\",\n",
    "    \"coreference resolution\", \"relation extraction\", \"information extraction\",\n",
    "    \"knowledge graphs\", \"ontologies\", \"semantic role labeling\", \"SRL\",\n",
    "    \"document retrieval\", \"passage retrieval\", \"question answering systems\",\n",
    "    \"retrieval-augmented generation\", \"RAG\", \"open-domain QA\", \"closed-domain QA\",\n",
    "    \"query expansion\", \"query reformulation\", \"interactive information retrieval\",\n",
    "    \"user modeling\", \"personalized search\", \"context-aware retrieval\",\n",
    "    \"query understanding\", \"query intent\", \"search engine optimization\", \"SEO\",\n",
    "    \"click-through rate\", \"CTR\", \"session-based search\", \"search result diversification\",\n",
    "    \"exploratory search\", \"faceted search\", \"enterprise search\",\n",
    "    \"legal information retrieval\", \"medical information retrieval\",\n",
    "    \"scientific information retrieval\", \"scholarly search\", \"academic search\",\n",
    "    \"digital libraries\", \"citation analysis\", \"bibliometrics\", \"altmetrics\",\n",
    "    \"author disambiguation\", \"document clustering\", \"document classification\",\n",
    "    \"information visualization\", \"search interfaces\", \"human-computer interaction\",\n",
    "    \"HCI\", \"recommendation systems\", \"collaborative filtering\", \"content-based filtering\",\n",
    "    \"hybrid recommendation\", \"ranking algorithms\", \"learning to rank\", \"LTR\",\n",
    "    \"pairwise ranking\", \"listwise ranking\", \"pointwise ranking\", \"click models\",\n",
    "    \"user feedback\", \"implicit feedback\", \"explicit feedback\", \"active learning\",\n",
    "    \"crowdsourcing\", \"data annotation\", \"evaluation metrics\", \"benchmark datasets\"\n",
    "]\n",
    "\n",
    "def advanced_segment_query(query):\n",
    "    ner_results = nlp(query)\n",
    "    segments = set(result['word'] for result in ner_results if result['entity'] in ['B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'])\n",
    "    for term in domain_specific_terms:\n",
    "        if term.lower() in query.lower():  # Case-insensitive matching\n",
    "            segments.add(term)\n",
    "    if not segments:\n",
    "        segments = word_tokenize(query)\n",
    "    return \" \".join(segments)\n",
    "\n",
    "print('\\n Segmenting the queries...')\n",
    "segmented_topics = topics.copy()\n",
    "segmented_topics['query'] = segmented_topics['query'].apply(advanced_segment_query)\n",
    "print(segmented_topics.head(3))\n",
    "\n",
    "print('\\n Now we do the retrieval...')\n",
    "run = combined_pipeline.transform(segmented_topics)\n",
    "\n",
    "print('\\n Done. Here are the first 10 entries of the run')\n",
    "print(run.head(10))\n",
    "\n",
    "# Definiere mögliche Ausgabeverzeichnisse\n",
    "output_dirs = [\n",
    "    os.environ.get('outputDir', '/output'),  # TIRA-spezifisches Verzeichnis\n",
    "    '../runs',  # Lokales Verzeichnis außerhalb der Sandbox\n",
    "    '.'  # Aktuelles Verzeichnis als Fallback\n",
    "]\n",
    "\n",
    "# Versuche, in jedes Verzeichnis zu schreiben, bis es klappt\n",
    "for output_dir in output_dirs:\n",
    "    try:\n",
    "        if output_dir != '/output':  # Wir wissen, dass /output schreibgeschützt ist\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "        run_file_path = os.path.join(output_dir, 'run.txt')\n",
    "        run.to_csv(run_file_path, sep='\\t', index=False, header=False)\n",
    "        logging.info(f\"Results saved to {run_file_path}\")\n",
    "        break  # Beende die Schleife, wenn das Schreiben erfolgreich war\n",
    "    except OSError as e:\n",
    "        logging.warning(f\"Could not save to {output_dir}: {str(e)}\")\n",
    "else:\n",
    "    logging.error(\"Failed to save results to any output directory\")\n",
    "    raise RuntimeError(\"No writable output directory found\")\n",
    "\n",
    "# Persistiere und normalisiere den Run, falls möglich\n",
    "try:\n",
    "    persist_and_normalize_run(run, system_name='combined-bm25-bo1-tfidf-dirichlet', default_output='../runs')\n",
    "except Exception as e:\n",
    "    logging.warning(f\"Could not persist and normalize run: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Persist the run file for subsequent evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../runs\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:An error occurred while saving the run file: Cannot save file into a non-existent directory: '/output'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. run file is stored under \"../runs/run.txt\".\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '/output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     persist_and_normalize_run(run, system_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined-bm25-bo1-tfidf-dirichlet\u001b[39m\u001b[38;5;124m'\u001b[39m, default_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../runs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m     output_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputDir\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/output\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages/pandas/core/generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3891\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3900\u001b[0m )\n\u001b[0;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3905\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3907\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3914\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages/pandas/io/formats/format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1151\u001b[0m )\n\u001b[0;32m-> 1152\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages/pandas/io/formats/csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    264\u001b[0m     )\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages/pandas/io/common.py:739\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 739\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/irs-combined-github/ir-lab-sose-2024-eric-martin-malcolm-till/.venv/lib/python3.11/site-packages/pandas/io/common.py:604\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    602\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/output'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.makedirs('../runs', exist_ok=True)\n",
    "    persist_and_normalize_run(run, system_name='combined-bm25-bo1-tfidf-dirichlet', default_output='../runs')\n",
    "    output_dir = os.environ.get('outputDir', '/output')\n",
    " \n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred while saving the run file: {str(e)}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
