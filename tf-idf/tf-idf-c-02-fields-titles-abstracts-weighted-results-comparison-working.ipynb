{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IR Lab SoSe 2024: Vergleichendes Retrieval System (Korrigierte Version)\n",
    "\n",
    "Dieses Jupyter Notebook implementiert und vergleicht mehrere Retrieval-Ansätze:\n",
    "1. Nur BM25\n",
    "2. BM25 + TF-IDF\n",
    "3. BM25 + Gewichtetes TF-IDF (mit Feldgewichtung)\n",
    "\n",
    "Wir verwenden ein Korpus wissenschaftlicher Arbeiten (Titel + Abstracts) aus den Bereichen Information Retrieval und Natural Language Processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 1: Bibliotheken importieren und Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "PyTerrier 0.10.1 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "from tira.rest_api_client import Client\n",
    "import pyterrier as pt\n",
    "from pyterrier.pipelines import *\n",
    "import pandas as pd\n",
    "\n",
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()\n",
    "\n",
    "# Das Dataset und der Index\n",
    "pt_dataset = pt.get_dataset('irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training')\n",
    "index = tira.pt.index('ir-lab-sose-2024/tira-ir-starter/Index (tira-ir-starter-pyterrier)', pt_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 2: Retrieval Pipelines definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Nur BM25\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "\n",
    "# 2. BM25 + TF-IDF\n",
    "tfidf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n",
    "bm25_tfidf = bm25 >> tfidf\n",
    "\n",
    "# 3. BM25 + Gewichtetes TF-IDF\n",
    "fields = [\"title\", \"abstract\"]\n",
    "weights = [2.0, 1.0]  # Titel hat doppeltes Gewicht des Abstracts\n",
    "weighted_tfidf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\", controls={\"c\": 1.0}, fields=fields)\n",
    "for field, weight in zip(fields, weights):\n",
    "    weighted_tfidf.controls[f\"w.{field}\"] = weight\n",
    "bm25_weighted_tfidf = bm25 >> weighted_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 3: Retrieval durchführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die ersten drei Topics:\n",
      "  qid                                     query\n",
      "0   1  retrieval system improving effectiveness\n",
      "1   2  machine learning language identification\n",
      "2   3             social media detect self harm\n",
      "\n",
      "Führe Retrieval für alle Ansätze durch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(TF_IDF): 100%|██████████| 68/68 [00:01<00:00, 58.54q/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval abgeschlossen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "topics = pt_dataset.get_topics('text')\n",
    "print('Die ersten drei Topics:')\n",
    "print(topics.head(3))\n",
    "\n",
    "print('\\nFühre Retrieval für alle Ansätze durch...')\n",
    "run_bm25 = bm25(topics)\n",
    "run_bm25_tfidf = bm25_tfidf(topics)\n",
    "run_bm25_weighted_tfidf = bm25_weighted_tfidf(topics)\n",
    "print('Retrieval abgeschlossen.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 4: Ergebnisse vergleichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5k/bwdc2gb51ns2k5373w3_1bhc0000gn/T/ipykernel_53276/882547094.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  results[name] = run.groupby('qid').apply(lambda x: x.head(k)).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vergleich der Top 10 Ergebnisse für die erste Anfrage (qid=1):\n",
      "  BM25_qid                          BM25_docno  BM25_score BM25+TF-IDF_qid  \\\n",
      "0        1        2004.cikm_conference-2004.47   15.681777               1   \n",
      "1        1   1989.ipm_journal-ir0volumeA25A4.2   15.047380               1   \n",
      "2        1  2005.ipm_journal-ir0volumeA41A5.11   14.144223               1   \n",
      "3        1                            W05-0704   14.025748               1   \n",
      "4        1       2016.ntcir_conference-2016.90   13.947994               1   \n",
      "5        1     1998.sigirconf_conference-98.15   13.901647               1   \n",
      "6        1       2008.cikm_conference-2008.183   13.808208               1   \n",
      "7        1                            O01-2005   13.749449               1   \n",
      "8        1     1998.sigirconf_conference-98.33   13.735541               1   \n",
      "9        1   2006.ipm_journal-ir0volumeA42A3.2   13.569263               1   \n",
      "\n",
      "                    BM25+TF-IDF_docno  BM25+TF-IDF_score  \\\n",
      "0        2004.cikm_conference-2004.47          10.432440   \n",
      "1   1989.ipm_journal-ir0volumeA25A4.2           9.971822   \n",
      "2  2005.ipm_journal-ir0volumeA41A5.11           9.255656   \n",
      "3     1998.sigirconf_conference-98.33           9.133236   \n",
      "4       2008.cikm_conference-2008.183           9.126181   \n",
      "5       2016.ntcir_conference-2016.90           9.118799   \n",
      "6     1998.sigirconf_conference-98.15           9.104662   \n",
      "7   2008.ipm_journal-ir0volumeA44A3.9           8.925898   \n",
      "8                            O01-2005           8.922977   \n",
      "9   2006.ipm_journal-ir0volumeA42A3.2           8.907615   \n",
      "\n",
      "  BM25+Weighted-TF-IDF_qid         BM25+Weighted-TF-IDF_docno  \\\n",
      "0                        1  1989.ipm_journal-ir0volumeA25A4.2   \n",
      "1                        1       2004.cikm_conference-2004.47   \n",
      "2                        1       2003.trec_conference-2003.21   \n",
      "3                        1  2002.ipm_journal-ir0volumeA38A1.0   \n",
      "4                        1       1998.trec_conference-1998.34   \n",
      "5                        1                           O07-2010   \n",
      "6                        1          2016.iir_workshop-2016.13   \n",
      "7                        1       2010.riao_conference-2010.33   \n",
      "8                        1        2017.airs_conference-2017.1   \n",
      "9                        1       2004.ecir_conference-2004.21   \n",
      "\n",
      "   BM25+Weighted-TF-IDF_score  \n",
      "0                   12.493450  \n",
      "1                   10.246570  \n",
      "2                   10.035867  \n",
      "3                   10.035867  \n",
      "4                    9.866787  \n",
      "5                    9.545162  \n",
      "6                    9.545162  \n",
      "7                    9.545162  \n",
      "8                    9.545162  \n",
      "9                    9.545162  \n",
      "\n",
      "Überlappung der Top 10 Ergebnisse zwischen den Ansätzen:\n",
      "BM25 vs BM25+TF-IDF: 615 von 10\n",
      "BM25 vs BM25+Weighted-TF-IDF: 301 von 10\n",
      "BM25+TF-IDF vs BM25+Weighted-TF-IDF: 299 von 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5k/bwdc2gb51ns2k5373w3_1bhc0000gn/T/ipykernel_53276/882547094.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  results[name] = run.groupby('qid').apply(lambda x: x.head(k)).reset_index(drop=True)\n",
      "/var/folders/5k/bwdc2gb51ns2k5373w3_1bhc0000gn/T/ipykernel_53276/882547094.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  results[name] = run.groupby('qid').apply(lambda x: x.head(k)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "def compare_top_k(runs, k=10):\n",
    "    results = {}\n",
    "    for name, run in runs.items():\n",
    "        results[name] = run.groupby('qid').apply(lambda x: x.head(k)).reset_index(drop=True)\n",
    "    \n",
    "    comparison = pd.DataFrame()\n",
    "    for name, result in results.items():\n",
    "        comparison[f'{name}_qid'] = result['qid']\n",
    "        comparison[f'{name}_docno'] = result['docno']\n",
    "        comparison[f'{name}_score'] = result['score']\n",
    "    \n",
    "    return comparison\n",
    "\n",
    "runs = {\n",
    "    'BM25': run_bm25,\n",
    "    'BM25+TF-IDF': run_bm25_tfidf,\n",
    "    'BM25+Weighted-TF-IDF': run_bm25_weighted_tfidf\n",
    "}\n",
    "\n",
    "comparison = compare_top_k(runs)\n",
    "print(f'Vergleich der Top 10 Ergebnisse für die erste Anfrage (qid=1):')\n",
    "print(comparison[comparison['BM25_qid'] == '1'])\n",
    "\n",
    "# Berechnen Sie den Overlap zwischen den Top-K Ergebnissen\n",
    "def calculate_overlap(runs, k=10):\n",
    "    overlaps = {}\n",
    "    for name1, run1 in runs.items():\n",
    "        for name2, run2 in runs.items():\n",
    "            if name1 < name2:  # Vermeiden Sie doppelte Vergleiche\n",
    "                overlap = len(set(run1.groupby('qid').head(k)['docno']) & \n",
    "                              set(run2.groupby('qid').head(k)['docno']))\n",
    "                overlaps[f'{name1} vs {name2}'] = overlap\n",
    "    return overlaps\n",
    "\n",
    "overlaps = calculate_overlap(runs)\n",
    "print(f'\\nÜberlappung der Top 10 Ergebnisse zwischen den Ansätzen:')\n",
    "for comparison, overlap in overlaps.items():\n",
    "    print(f'{comparison}: {overlap} von 10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 5: Run-Dateien persistieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../runs\".\n",
      "Done. run file is stored under \"../runs/run.txt\".\n",
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../runs\".\n",
      "Done. run file is stored under \"../runs/run.txt\".\n",
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../runs\".\n",
      "Done. run file is stored under \"../runs/run.txt\".\n"
     ]
    }
   ],
   "source": [
    "persist_and_normalize_run(run_bm25, system_name='bm25-baseline', default_output='../runs')\n",
    "persist_and_normalize_run(run_bm25_tfidf, system_name='bm25-tfidf-combined', default_output='../runs')\n",
    "persist_and_normalize_run(run_bm25_weighted_tfidf, system_name='bm25-weighted-tfidf-combined', default_output='../runs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 6: Analyse und Interpretation\n",
    "\n",
    "1. Betrachten Sie die Top-10-Ergebnisse für verschiedene Anfragen. Wie unterscheiden sich die Ergebnisse zwischen den Ansätzen?\n",
    "\n",
    "2. Analysieren Sie die Überlappung der Ergebnisse. Ein hoher Überlappungsgrad deutet darauf hin, dass die Ansätze ähnliche Ergebnisse liefern, während ein niedriger Grad auf unterschiedliche Stärken der Ansätze hinweisen könnte.\n",
    "\n",
    "3. Untersuchen Sie spezifische Fälle, in denen die gewichtete TF-IDF-Methode andere Ergebnisse liefert als die anderen Methoden. Sind diese Unterschiede auf die Titelgewichtung zurückzuführen?\n",
    "\n",
    "4. Betrachten Sie die Scores der verschiedenen Methoden. Wie unterscheiden sie sich in ihrer Verteilung und Größenordnung?\n",
    "\n",
    "5. Für eine gründlichere Evaluation wären Relevanzurteile erforderlich, um Metriken wie MAP oder NDCG zu berechnen. In Ermangelung solcher Urteile könnten Sie eine manuelle Stichprobenprüfung der Ergebnisse für einige ausgewählte Anfragen durchführen.\n",
    "\n",
    "6. Überlegen Sie, wie Sie die Ansätze weiter verbessern könnten. Mögliche Richtungen umfassen:\n",
    "   - Experimentieren mit verschiedenen Feldgewichten\n",
    "   - Einbeziehung zusätzlicher Felder (z.B. Autorennamen, Veröffentlichungsjahr)\n",
    "   - Implementierung von Query Expansion oder Pseudo-Relevanz-Feedback\n",
    "   - Verwendung von neueren Ranking-Modellen wie BERT oder andere Transformer-basierte Modelle\n",
    "\n",
    "Denken Sie daran, dass die 'beste' Methode oft von der spezifischen Aufgabe und dem Datensatz abhängt. Eine gründliche Evaluation und Analyse ist entscheidend, um zu verstehen, welcher Ansatz für Ihre spezifischen Bedürfnisse am besten geeignet ist."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
